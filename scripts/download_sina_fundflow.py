# scripts/download_sina_fundflow.py
# 2025-11-17 çœŸæ­£å…¨å¸‚åœºç‰ˆï¼šä¸ªè‚¡ç”¨æ–°æµªï¼ŒæŒ‡æ•°è‡ªåŠ¨åˆ‡ä¸œè´¢ï¼Œ0 ä¸¢è‚¡ï¼

import os
import json
import requests
import pandas as pd
from tqdm import tqdm
import time
import sys

# ==================== é…ç½® ====================
OUTPUT_DIR = "data_fundflow"
PAGE_SIZE = 50
TASK_INDEX = int(os.getenv("TASK_INDEX", 0))
os.makedirs(OUTPUT_DIR, exist_ok=True)

# æ–°æµªæ¥å£ï¼ˆä¸ªè‚¡ï¼‰
SINA_API = "https://vip.stock.finance.sina.com.cn/quotes_service/api/json_v2.php/MoneyFlow.ssl_qsfx_lscjfb"

# ä¸œè´¢æ¥å£ï¼ˆæŒ‡æ•°ä¸“ç”¨ï¼‰
EM_API = "http://push2.eastmoney.com/api/qt/stock/fflow/daykline/get"

HEADERS_SINA = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Referer': 'https://vip.stock.finance.sina.com.cn/'
}

HEADERS_EM = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
    "Referer": "https://quote.eastmoney.com/"
}

COLUMN_MAP = {
    'opendate': 'date', 'trade': 'close', 'changeratio': 'pct_change',
    'turnover': 'turnover_rate', 'netamount': 'net_flow_amount',
    'r0_net': 'main_net_flow', 'r1_net': 'super_large_net_flow',
    'r2_net': 'large_net_flow', 'r3_net': 'medium_small_net_flow'
}

# ==================== è¾…åŠ©å‡½æ•° ====================
def is_index(code: str) -> bool:
    """æ ¹æ®ä»£ç å‰ç¼€åˆ¤æ–­æ˜¯å¦ä¸ºæŒ‡æ•°"""
    if not isinstance(code, str) or len(code) < 6:
        return False
    # ä¸Šè¯æŒ‡æ•° (000xxx), æ·±è¯æŒ‡æ•° (399xxx), ä»¥åŠä¸€äº›è¡Œä¸š/æ¦‚å¿µæŒ‡æ•°
    num = code[3:6]
    return num in ['000','900','399','880','950','951','952','953','899']

def get_sina_fundflow(code: str) -> pd.DataFrame:
    """ä»æ–°æµªè·å–ä¸ªè‚¡çš„å†å²èµ„é‡‘æµ (åˆ†é¡µ)"""
    all_data = []
    page = 1
    code_api = code.replace('.', '')
    while True:
        url = f"{SINA_API}?page={page}&num={PAGE_SIZE}&sort=opendate&asc=0&daima={code_api}"
        try:
            r = requests.get(url, headers=HEADERS_SINA, timeout=30)
            r.raise_for_status()
            r.encoding = 'gbk'
            data = r.json()
            if not data: break
            all_data.extend(data)
            if len(data) < PAGE_SIZE: break
            page += 1
            time.sleep(0.3)
        except Exception:
            # ä»»ä½•é”™è¯¯éƒ½ä¸­æ–­å½“å‰è‚¡ç¥¨çš„ä¸‹è½½
            break
    return pd.DataFrame(all_data) if all_data else pd.DataFrame()

def get_em_fundflow_index(code: str) -> pd.DataFrame:
    """ä¸“ä¸ºæŒ‡æ•°å‡†å¤‡çš„ä¸œè´¢æ¥å£ï¼ˆå­—æ®µå®Œç¾å¯¹é½ï¼‰"""
    prefix = "1." if code.startswith("sh") else "0."
    secid = prefix + code[3:]
    # æ³¨æ„: ä¸œè´¢è¿”å›çš„é‡‘é¢å•ä½æ˜¯â€œå…ƒâ€ï¼Œæ–°æµªæ˜¯â€œä¸‡â€ï¼Œè¿™é‡Œéœ€è¦ç»Ÿä¸€
    # æˆ‘ä»¬åœ¨ main å‡½æ•°çš„æ¸…æ´—é˜¶æ®µè¿›è¡Œç»Ÿä¸€ï¼Œè¿™é‡Œå…ˆè·å–åŸå§‹æ•°æ®
    params = {
        "lmt": "0", # è·å–å…¨éƒ¨å†å²
        "klt": "101", # æ—¥çº¿
        "fields1": "f1,f2,f3,f7",
        "fields2": "f51,f52,f53,f54,f55,f56,f57,f58,f59",
        "secid": secid,
    }
    try:
        r = requests.get(EM_API, params=params, headers=HEADERS_EM, timeout=20)
        r.raise_for_status()
        j = r.json()
        klines = j.get("data", {}).get("klines", [])
        if not klines:
            return pd.DataFrame()
            
        records = []
        for line in klines:
            items = line.split(",")
            if len(items) >= 9:
                records.append({
                    "opendate": items[0],
                    "trade": items[1],
                    "changeratio": items[2],
                    "turnover": None,  # æŒ‡æ•°æ— æ¢æ‰‹ç‡
                    "netamount": items[8],     
                    "r0_net": items[4],
                    "r1_net": items[5],
                    "r2_net": items[6],
                    "r3_net": items[7],
                })
        return pd.DataFrame(records)
    except Exception:
        return pd.DataFrame()

def get_fundflow_smart(code: str) -> pd.DataFrame:
    """æ™ºèƒ½é€‰æ‹©æ•°æ®æº"""
    if is_index(code):
        print(f"  â†’ æ£€æµ‹ä¸ºæŒ‡æ•° {code}ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸œæ–¹è´¢å¯Œæ¥å£...")
        return get_em_fundflow_index(code)
    else:
        return get_sina_fundflow(code)

# ==================== ä¸»æµç¨‹ ====================
def main():
    print(f"\n2025å…¨å¸‚åœºèµ„é‡‘æµä¸‹è½½ï¼ˆä¸ªè‚¡æ–°æµª+æŒ‡æ•°ä¸œè´¢ï¼‰- åˆ†åŒº {TASK_INDEX + 1}")

    task_file = f"tasks/task_slice_{TASK_INDEX}.json"
    try:
        with open(task_file) as f:
            stocks = json.load(f)
    except FileNotFoundError:
        print(f"âŒ è‡´å‘½é”™è¯¯: æœªæ‰¾åˆ°ä»»åŠ¡åˆ†ç‰‡æ–‡ä»¶ {task_file}ï¼"); sys.exit(1)


    print(f"æœ¬åˆ†åŒºå…± {len(stocks)} åªï¼ˆå«æŒ‡æ•°ï¼‰")
    success_count = 0

    for s in tqdm(stocks, desc=f"åˆ†åŒº {TASK_INDEX+1} ä¸‹è½½ä¸­"):
        code = s["code"]
        name = s.get("name", "")
        
        df_raw = get_fundflow_smart(code)

        if df_raw.empty:
            print(f"  -> ğŸŸ¡ {name} ({code}) æœªä¸‹è½½åˆ°æ•°æ®ã€‚")
            continue

        # --- ç»Ÿä¸€çš„æ•°æ®æ¸…æ´—å’Œæ ¼å¼åŒ– ---
        try:
            # ç»Ÿä¸€åˆ—å
            df_renamed = df_raw.rename(columns=COLUMN_MAP)
            
            # æ·»åŠ  code åˆ—
            df_renamed['code'] = code

            # ç­›é€‰å‡ºæˆ‘ä»¬éœ€è¦çš„æ ‡å‡†åˆ—
            final_cols = [
                'date', 'code', 'close', 'pct_change', 'turnover_rate',
                'net_flow_amount', 'main_net_flow', 'super_large_net_flow',
                'large_net_flow', 'medium_small_net_flow'
            ]
            # æ£€æŸ¥å“ªäº›åˆ—æ˜¯å¯ç”¨çš„
            available_cols = [c for c in final_cols if c in df_renamed.columns]
            df_cleaned = df_renamed[available_cols]

            # ç»Ÿä¸€æ•°æ®ç±»å‹
            if 'date' in df_cleaned.columns:
                df_cleaned['date'] = pd.to_datetime(df_cleaned['date'], errors='coerce')
            
            numeric_cols = [c for c in df_cleaned.columns if c not in ['date', 'code']]
            df_cleaned[numeric_cols] = df_cleaned[numeric_cols].apply(pd.to_numeric, errors='coerce')
            
            # (é‡è¦) å•ä½ç»Ÿä¸€ï¼šä¸œè´¢çš„é‡‘é¢å•ä½æ˜¯â€œå…ƒâ€ï¼Œæ–°æµªæ˜¯â€œä¸‡â€ã€‚ç»Ÿä¸€è½¬æ¢ä¸ºâ€œå…ƒâ€ã€‚
            # æˆ‘ä»¬å‡è®¾æ–°æµªçš„å­—æ®µååŒ…å« 'netamount' æˆ– '_net'
            if not is_index(code): # å¦‚æœæ˜¯ä¸ªè‚¡ï¼ˆæ¥è‡ªæ–°æµªï¼‰
                money_cols = [c for c in df_cleaned.columns if 'amount' in c or 'flow' in c]
                df_cleaned[money_cols] = df_cleaned[money_cols] * 10000

            # æ’åºå¹¶ä¿å­˜
            df_final = df_cleaned.sort_values('date').reset_index(drop=True)
            output_path = f"{OUTPUT_DIR}/{code}.parquet"
            df_final.to_parquet(output_path, index=False, compression='zstd' if 'zstandard' in sys.modules else 'snappy')
            success_count += 1
            
        except Exception as e:
            print(f"  -> âŒ åœ¨å¤„ç† {name} ({code}) çš„æ•°æ®æ—¶å‡ºé”™: {e}")


    print(f"\nåˆ†åŒº {TASK_INDEX + 1} å®Œæˆï¼æˆåŠŸä¸‹è½½ {success_count}/{len(stocks)} åªï¼ˆå«æŒ‡æ•°ï¼‰")
    if success_count == 0 and len(stocks) > 0:
        exit(1)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒâŒâŒ åœ¨ main å‡½æ•°é¡¶å±‚æ•è·åˆ°è‡´å‘½å¼‚å¸¸: {e} âŒâŒâŒ")
        traceback.print_exc()
        exit(1)
