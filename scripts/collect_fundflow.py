# scripts/collect_fundflow.py
# 2025-11-18 æœ€ç»ˆç®€åŒ–ç‰ˆï¼šä¿¡ä»»ä¸Šæ¸¸å·²å®Œæˆæ•°æ®æ¸…æ´—ï¼Œä¸“æ³¨äºå†…å­˜å®‰å…¨çš„åˆå¹¶ã€æ’åºä¸è´¨æ£€

import os
import pandas as pd
import glob
from tqdm import tqdm
import json
from datetime import datetime
import shutil
import sys
import traceback

# å°è¯•å¯¼å…¥æ ¸å¿ƒåº“
try:
    import pyarrow.parquet as pq
    import pyarrow as pa
    import duckdb
    PYARROW_DUCKDB_AVAILABLE = True
except ImportError:
    PYARROW_DUCKDB_AVAILABLE = False

# ==================== é…ç½® ====================
INPUT_BASE_DIR = "all_fundflow"
SMALL_OUTPUT_DIR = "fundflow_small"
TEMP_UNSORTED_FILE = "full_fundflow_unsorted.parquet"
FINAL_PARQUET_FILE = "full_fundflow.parquet"
QUALITY_REPORT_FILE = "data_quality_report_fundflow.json"

os.makedirs(SMALL_OUTPUT_DIR, exist_ok=True)

# ==================== ç³»ç»Ÿèµ„æºç›‘æ§å‡½æ•° ====================
def print_system_stats():
    """æ‰“å°å½“å‰çš„å†…å­˜å’Œç¡¬ç›˜ä½¿ç”¨æƒ…å†µ"""
    # ... (æ­¤å‡½æ•°ä¿æŒä¸å˜)
    print("-" * 20)
    try:
        import psutil
        mem = psutil.virtual_memory()
        print(f"  -> ğŸ“Š RAM Usage: {mem.used / (1024**3):.2f} GB / {mem.total / (1024**3):.2f} GB ({mem.percent}%)")
    except ImportError:
        pass
    try:
        disk = shutil.disk_usage("/")
        print(f"  -> ğŸ“Š Disk Usage: {disk.used / (1024**3):.2f} GB / {disk.total / (1024**3):.2f} GB ({disk.used / disk.total * 100:.1f}%)")
    except Exception:
        pass
    print("-" * 20)

# ==================== ä¸»æµç¨‹ ====================
def main():
    if not PYARROW_DUCKDB_AVAILABLE:
        print("âŒ è‡´å‘½é”™è¯¯: æœªæ‰¾åˆ° 'pyarrow' æˆ– 'duckdb' åº“ã€‚")
        sys.exit(1)
        
    print("å¼€å§‹ èµ„é‡‘æµæ•°æ®æ”¶é›†ä¸åˆå¹¶æµç¨‹...")
    print_system_stats()

    search_pattern = os.path.join(INPUT_BASE_DIR, "**", "*.parquet")
    files = glob.glob(search_pattern, recursive=True)
    
    if not files:
        print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åˆ†ç‰‡æ–‡ä»¶ï¼Œé€€å‡ºã€‚"); return
        
    print(f"å‘ç° {len(files)} ä¸ªèµ„é‡‘æµåˆ†ç‰‡æ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...")

    # --- é˜¶æ®µ 1: å¤åˆ¶å°æ–‡ä»¶ ---
    if os.path.exists(SMALL_OUTPUT_DIR): shutil.rmtree(SMALL_OUTPUT_DIR)
    os.makedirs(SMALL_OUTPUT_DIR, exist_ok=True)
    for f in tqdm(files, desc="å¤åˆ¶èµ„é‡‘æµå°æ–‡ä»¶"):
        filename = os.path.basename(f)
        shutil.copy2(f, os.path.join(SMALL_OUTPUT_DIR, filename))
    print(f"æ‰€æœ‰å°æ–‡ä»¶å·²æ”¶é›†è‡³ {SMALL_OUTPUT_DIR}/")

    # --- é˜¶æ®µ 2: æµå¼å†™å…¥æœªæ’åºçš„åˆå¹¶æ–‡ä»¶ ---
    chunk_size = 2000
    writer = None
    print(f"\nå°†ä»¥æµå¼å†™å…¥æ¨¡å¼åˆå¹¶ï¼Œæ¯å— {chunk_size} ä¸ªæ–‡ä»¶...")
    try:
        for i in tqdm(range(0, len(files), chunk_size), desc="åˆ†å—å†™å…¥ Parquet ä¸­"):
            chunk_files = files[i : i + chunk_size]
            
            # (å…³é”®ç®€åŒ–) ä¸å†éœ€è¦è°ƒç”¨ unify_columns
            dfs = [pd.read_parquet(f) for f in chunk_files]
            chunk_df = pd.concat(dfs, ignore_index=True)
            
            table = pa.Table.from_pandas(chunk_df, preserve_index=False)
            if writer is None:
                writer = pq.ParquetWriter(TEMP_UNSORTED_FILE, table.schema, compression='zstd' if 'zstandard' in sys.modules else 'snappy')
            writer.write_table(table)
            
            print(f"\nå— {i//chunk_size + 1} å†™å…¥å®Œæˆã€‚")
            print_system_stats()
    finally:
        if writer:
            writer.close()
            print("\nParquet writer å·²å…³é—­ã€‚")

    # --- é˜¶æ®µ 3: ä½¿ç”¨ DuckDB è¿›è¡Œå†…å­˜å®‰å…¨çš„å¤–éƒ¨æ’åº ---
    print(f"\nåˆå¹¶å†™å…¥å®Œæˆï¼Œæ–‡ä»¶ä¸º {TEMP_UNSORTED_FILE}ã€‚å‡†å¤‡ä½¿ç”¨ DuckDB è¿›è¡Œå¤–éƒ¨æ’åº...")
    print_system_stats()
    
    try:
        con = duckdb.connect()
        con.execute("SET memory_limit='5GB';") 
        
        query = f"""
        COPY (
            SELECT * 
            FROM read_parquet('{TEMP_UNSORTED_FILE}')
            ORDER BY code, date
        ) TO '{FINAL_PARQUET_FILE}' (FORMAT PARQUET, COMPRESSION 'ZSTD');
        """
        
        print("... æ­£åœ¨æ‰§è¡Œ DuckDB æ’åºå’Œå†™å…¥ ...")
        con.execute(query)
        con.close()
        
        print(f"âœ… DuckDB æ’åºå®Œæˆï¼å·²ç”Ÿæˆæœ€ç»ˆæ’åºæ–‡ä»¶: {FINAL_PARQUET_FILE}")
        os.remove(TEMP_UNSORTED_FILE)
        print_system_stats()
        
    except Exception as e:
        print(f"\nâŒ åœ¨ DuckDB æ’åºé˜¶æ®µå‘ç”Ÿé”™è¯¯: {e}")
        traceback.print_exc()
        if os.path.exists(TEMP_UNSORTED_FILE):
            os.rename(TEMP_UNSORTED_FILE, FINAL_PARQUET_FILE)

    # --- é˜¶æ®µ 4: ç”Ÿæˆè´¨æ£€æŠ¥å‘Š ---
    print("\næ­£åœ¨è¯»å–æœ€ç»ˆæ–‡ä»¶è¿›è¡Œè´¨æ£€...")
    if os.path.exists(FINAL_PARQUET_FILE):
        final_df = pd.read_parquet(FINAL_PARQUET_FILE)
        
        print("\næ­£åœ¨ç”Ÿæˆè´¨æ£€æŠ¥å‘Š...")
        report = {
            "generate_time": datetime.now().isoformat(),
            "total_rows": len(final_df),
            "total_stocks_and_indices": final_df['code'].nunique(),
            "date_range": {
                "min": final_df['date'].min().date().isoformat() if pd.notna(final_df['date'].min()) else None,
                "max": final_df['date'].max().date().isoformat() if pd.notna(final_df['date'].max()) else None
            },
            "columns": list(final_df.columns),
            "nan_values": final_df.isnull().sum()[final_df.isnull().sum() > 0].to_dict(),
            "dtypes": final_df.dtypes.apply(lambda x: str(x)).to_dict()
        }
        with open(QUALITY_REPORT_FILE, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        print(f"è´¨æ£€æŠ¥å‘Šå·²ç”Ÿæˆï¼š{QUALITY_REPORT_FILE}")

        print("\nèµ„é‡‘æµå…¨å¸‚åœºæ•°æ®åˆå¹¶å®Œæˆï¼")
        print(f"â†’ æ€»è¡Œæ•°ï¼š{report['total_rows']:,}")
        print(f"â†’ æ ‡çš„æ€»æ•°ï¼ˆå«æŒ‡æ•°ï¼‰ï¼š{report['total_stocks_and_indices']:,}")
        print(f"â†’ æ—¥æœŸèŒƒå›´ï¼š{report['date_range']['min']} ~ {report['date_range']['max']}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°æœ€ç»ˆçš„ Parquet æ–‡ä»¶ï¼Œæ— æ³•ç”Ÿæˆè´¨æ£€æŠ¥å‘Šã€‚")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"\nâŒâŒâŒ åœ¨ main å‡½æ•°é¡¶å±‚æ•è·åˆ°è‡´å‘½å¼‚å¸¸: {e} âŒâŒâŒ")
        traceback.print_exc()
        exit(1)
